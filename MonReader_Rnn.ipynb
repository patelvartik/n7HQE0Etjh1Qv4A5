{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d38b02",
   "metadata": {},
   "source": [
    "# MonoReader RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72efbdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef26e1",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88884098",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 4\n",
    "\n",
    "h, w =224, 224\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbe5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def get_images(path2ajpgs):\n",
    "    listOfClasses = os.listdir(path2ajpgs)\n",
    "    ids = []\n",
    "    labels = []\n",
    "    for catg in listOfClasses:\n",
    "        path2catg = os.path.join(path2ajpgs, catg)\n",
    "        listOfSubCats = os.listdir(path2catg)\n",
    "        path2subCats= [os.path.join(path2catg,los) for los in listOfSubCats]\n",
    "        ids.extend(path2subCats)\n",
    "        labels.extend([catg]*len(listOfSubCats))\n",
    "    return ids, labels, listOfClasses \n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, ids, labels, transform):      \n",
    "        self.transform = transform\n",
    "        self.ids = ids\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    def __getitem__(self, idx):\n",
    "        path2imgs=glob.glob(self.ids[idx]+\"/*.jpg\")\n",
    "        #path2imgs = path2imgs[:num_frames]\n",
    "        label = labels_dict[self.labels[idx]]\n",
    "        frames = []\n",
    "        for p2i in path2imgs:\n",
    "            frame = Image.open(p2i)\n",
    "            frames.append(frame)\n",
    "        seed = np.random.randint(1e9)        \n",
    "        frames_tr = []\n",
    "        for frame in frames:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            frame = self.transform(frame)\n",
    "            frames_tr.append(frame)\n",
    "        if len(frames_tr)>0:\n",
    "            frames_tr = torch.stack(frames_tr)\n",
    "        return frames_tr, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4084a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc43458",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = os.path.join('MonReader_images_Rnn', 'training')\n",
    "\n",
    "train_ids,train_labels,catgs = get_images(training_dir)\n",
    "\n",
    "train_transformer = transforms.Compose([\n",
    "            transforms.Resize((h,w)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),  \n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1,0.1)),    \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "            ])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b212a663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flip': 0, 'notflip': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict = {}\n",
    "ind = 0\n",
    "for uc in catgs:\n",
    "    labels_dict[uc] = ind\n",
    "    ind+=1\n",
    "labels_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b104cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "train_ds = VideoDataset(ids= train_ids, labels= train_labels, transform= train_transformer)\n",
    "print(len(train_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57fe731b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([21, 3, 224, 224]), 0, tensor(-2.1179), tensor(2.1694))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, label = train_ds[10]\n",
    "imgs.shape, label, torch.min(imgs), torch.max(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32a2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1802b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dir = os.path.join('MonReader_images_Rnn', 'testing')\n",
    "\n",
    "test_ids,test_labels,catgs = get_images(testing_dir)\n",
    "\n",
    "test_transformer = transforms.Compose([\n",
    "            transforms.Resize((h,w)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "            ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1743ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_ds = VideoDataset(ids= test_ids, labels= test_labels, transform= test_transformer)\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4522fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': 117, 'testing': 115}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes=dict()\n",
    "dataset_sizes['training']=len(train_ds)\n",
    "dataset_sizes['testing']=len(test_ds)\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2385203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_rnn(batch):\n",
    "    imgs_batch, label_batch = list(zip(*batch))\n",
    "    imgs_batch = [imgs for imgs in imgs_batch if len(imgs)>0]\n",
    "    label_batch = [torch.tensor(l) for l, imgs in zip(label_batch, imgs_batch) if len(imgs)>0]\n",
    "    imgs_tensor = torch.stack(imgs_batch)\n",
    "    labels_tensor = torch.stack(label_batch)\n",
    "    return imgs_tensor,labels_tensor\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size= 1,\n",
    "                        shuffle=True, collate_fn= collate_fn_rnn)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size= 1,\n",
    "                        shuffle=False, collate_fn= collate_fn_rnn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129692c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 3, 224, 224]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in train_dl:\n",
    "    print(xb.shape, yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e73eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 224, 224]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in test_dl:\n",
    "    print(xb.shape, yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b21049",
   "metadata": {},
   "source": [
    "## 2. Rnn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d688e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Resnt18Rnn(nn.Module):\n",
    "    def __init__(self, params_model):\n",
    "        super(Resnt18Rnn, self).__init__()\n",
    "        num_classes = params_model[\"num_classes\"]\n",
    "        dr_rate= params_model[\"dr_rate\"]\n",
    "        pretrained = params_model[\"pretrained\"]\n",
    "        rnn_hidden_size = params_model[\"rnn_hidden_size\"]\n",
    "        rnn_num_layers = params_model[\"rnn_num_layers\"]\n",
    "        \n",
    "        baseModel = models.resnet18(pretrained=pretrained)\n",
    "        num_features = baseModel.fc.in_features\n",
    "        baseModel.fc = Identity()\n",
    "        self.baseModel = baseModel\n",
    "        self.dropout= nn.Dropout(dr_rate)\n",
    "        self.rnn = nn.LSTM(num_features, rnn_hidden_size, rnn_num_layers)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        b_z, ts, c, h, w = x.shape\n",
    "        ii = 0\n",
    "        y = self.baseModel((x[:,ii]))\n",
    "        out, (hn, cn) = self.rnn(y.unsqueeze(1))\n",
    "        for ii in range(1, ts):\n",
    "            y = self.baseModel((x[:,ii]))\n",
    "            out, (hn, cn) = self.rnn(y.unsqueeze(1), (hn, cn))\n",
    "        out = self.dropout(out[:,-1])\n",
    "        out = self.fc1(out) \n",
    "        return out \n",
    "    \n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e46924c",
   "metadata": {},
   "source": [
    "### 2.1. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a10da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['training', 'testing']:\n",
    "            if phase == 'training':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "\n",
    "            dataloader = train_dl\n",
    "            if phase == 'testing':\n",
    "                dataloader = test_dl\n",
    "            # Iterate over data.\n",
    "            \n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'training'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'training':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'training':\n",
    "                scheduler.step(running_loss / dataset_sizes[phase])\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'testing' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87adafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_model={\n",
    "        \"num_classes\": 2,\n",
    "        \"dr_rate\": 0.1,\n",
    "        \"pretrained\" : True,\n",
    "        \"rnn_num_layers\": 1,\n",
    "        \"rnn_hidden_size\": 100,}\n",
    "model = Resnt18Rnn(params_model)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "opt = optim.Adam(model.parameters(), lr=3e-5)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7665711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "training Loss: 0.6978 Acc: 0.4872\n",
      "testing Loss: 0.6919 Acc: 0.5217\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "training Loss: 0.5944 Acc: 0.8632\n",
      "testing Loss: 0.7926 Acc: 0.3826\n",
      "\n",
      "Training complete in 5m 39s\n",
      "Best val Acc: 0.521739\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, loss_func, opt, lr_scheduler,\n",
    "                       num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e8122",
   "metadata": {},
   "source": [
    "### 2.2. Model Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9b8aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "was_training = model.training\n",
    "model.eval()\n",
    "\n",
    "y_train=[]\n",
    "y_train_pred=[]\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(torch.utils.data.DataLoader(train_ds)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_train.append(catgs[labels])\n",
    "        y_train_pred.append(catgs[preds])\n",
    "    y_train=pd.DataFrame(data=y_train)\n",
    "    y_train_pred=pd.DataFrame(data=y_train_pred)\n",
    "\n",
    "    model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a579989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.47863247863247865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        flip       0.54      0.45      0.49        65\n",
      "     notflip       0.43      0.52      0.47        52\n",
      "\n",
      "    accuracy                           0.48       117\n",
      "   macro avg       0.48      0.48      0.48       117\n",
      "weighted avg       0.49      0.48      0.48       117\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flip</th>\n",
       "      <th>notflip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flip</th>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notflip</th>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0        flip  notflip\n",
       "0                     \n",
       "flip       29       36\n",
       "notflip    25       27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "print('Train accuracy' ,accuracy_score(y_train,y_train_pred))\n",
    "\n",
    "print(classification_report(y_train,y_train_pred))\n",
    "pd.crosstab(y_train[0],y_train_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "846a9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "was_training = model.training\n",
    "model.eval()\n",
    "\n",
    "y_test=[]\n",
    "y_test_pred=[]\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(torch.utils.data.DataLoader(test_ds)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_test.append(catgs[labels])\n",
    "        y_test_pred.append(catgs[preds])\n",
    "    y_test=pd.DataFrame(data=y_test)\n",
    "    y_test_pred=pd.DataFrame(data=y_test_pred)\n",
    "\n",
    "    model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95d41046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.5217391304347826\n",
      "Test F1 0.5180952380952382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        flip       0.60      0.40      0.48        63\n",
      "     notflip       0.48      0.67      0.56        52\n",
      "\n",
      "    accuracy                           0.52       115\n",
      "   macro avg       0.54      0.53      0.52       115\n",
      "weighted avg       0.54      0.52      0.51       115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flip</th>\n",
       "      <th>notflip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flip</th>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notflip</th>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0        flip  notflip\n",
       "0                     \n",
       "flip       25       38\n",
       "notflip    17       35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test accuracy' ,accuracy_score(y_test,y_test_pred))\n",
    "\n",
    "print('Test F1' ,fbeta_score(y_test, y_test_pred, average='macro', beta=1))\n",
    "\n",
    "print(classification_report(y_test,y_test_pred))\n",
    "pd.crosstab(y_test[0],y_test_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3a84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eda1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
